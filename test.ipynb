{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_explain.nn.concepts import ConceptReasoningLayer, IntpLinearLayer, ConceptReasoningLayerMod, ReasoningLinearLayer\n",
    "import torch\n",
    "import torch_explain as te\n",
    "from torch_explain import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, c, y = datasets.xor(10)\n",
    "x_train, x_test, c_train, c_test, y_train, y_test = train_test_split(\n",
    "    x, c, y, test_size=0.33, random_state=42)\n",
    "\n",
    "embedding_size = 8\n",
    "concept_encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(x.shape[1], 10),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    te.nn.ConceptEmbedding(10, c.shape[1], embedding_size),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------#\n",
    "\n",
    "y_train = F.one_hot(y_train.long().ravel()).float()\n",
    "y_test = F.one_hot(y_test.long().ravel()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_encoder(x_train)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 23:18:00,497 - torch_explain.nn.concepts - INFO - sign attention: torch.Size([6, 2, 2])\n",
      "2024-06-14 23:18:00,498 - torch_explain.nn.concepts - INFO - filter attention: torch.Size([6, 2, 2])\n",
      "2024-06-14 23:18:00,499 - torch_explain.nn.concepts - INFO - C: torch.Size([6, 2])\n",
      "2024-06-14 23:18:00,501 - torch_explain.nn.concepts - INFO - Transformed: torch.Size([6, 2, 2])\n",
      "2024-06-14 23:18:00,502 - torch_explain.nn.concepts - INFO - Logits: torch.Size([6, 2])\n",
      "2024-06-14 23:18:00,504 - torch_explain.nn.concepts - INFO - Logits: tensor([[0.0434, 0.3113],\n",
      "        [0.0434, 0.3112],\n",
      "        [0.0434, 0.3115],\n",
      "        [0.0435, 0.3125],\n",
      "        [0.1865, 0.0071],\n",
      "        [0.1835, 0.0071]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2, 8]) torch.Size([6, 2])\n",
      "torch.Size([6, 2]) torch.Size([6, 2, 2]) torch.Size([6, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0434, 0.3113],\n",
       "        [0.0434, 0.3112],\n",
       "        [0.0434, 0.3115],\n",
       "        [0.0435, 0.3125],\n",
       "        [0.1865, 0.0071],\n",
       "        [0.1835, 0.0071]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "task_predictor = ConceptReasoningLayer(embedding_size, y_train.shape[1])\n",
    "model = torch.nn.Sequential(concept_encoder, task_predictor)\n",
    "\n",
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss = torch.nn.BCELoss()\n",
    "c_emb, c_pred = concept_encoder(x_train)\n",
    "print(c_emb.shape, c_pred.shape)\n",
    "y_pred , sign_attn , filter_attn = task_predictor(c_emb, c_pred, return_attn=True)\n",
    "print(y_pred.shape, sign_attn.shape, filter_attn.shape)\n",
    "\n",
    "global_explainer = ReasoningLinearLayer(sign_attn.shape[1], filter_attn.shape[1], y_train.shape[1], log=True, modality='Attention')\n",
    "global_explainer.train()\n",
    "global_explainer(sign_attn, filter_attn, y_train)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "# # loss_form = torch.nn.BCELoss()\n",
    "# loss_form = torch.nn.BCEWithLogitsLoss()\n",
    "# model.train()\n",
    "# for epoch in range(1):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # generate concept and task predictions\n",
    "#     c_emb, c_pred = concept_encoder(x_train)\n",
    "#     y_pred = task_predictor(c_emb, c_pred)\n",
    "    \n",
    "\n",
    "#     # compute loss\n",
    "#     concept_loss = loss_form(c_pred, c_train)\n",
    "#     task_loss = loss_form(y_pred, y_train)\n",
    "#     loss = concept_loss + 0.5*task_loss\n",
    "\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# local_explanations = task_predictor.explain(c_emb, c_pred, 'local')\n",
    "# global_explanations = task_predictor.explain(c_emb, c_pred, 'global')\n",
    "\n",
    "# # print(local_explanations)\n",
    "# print(global_explanations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_explain.nn.concepts import ConceptReasoningLayerMod\n",
    "dcrm = ConceptReasoningLayerMod(embedding_size, y_train.shape[1], log=False)\n",
    "dcrm(c_emb, c_pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6354, 0.7199],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5767, 0.6782],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7018, 0.7699]],\n",
       "\n",
       "        [[0.6355, 0.7198],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5758, 0.6773],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7017, 0.7698]],\n",
       "\n",
       "        [[0.6358, 0.7197],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5781, 0.6755],\n",
       "         [0.9948, 0.9960],\n",
       "         [0.9640, 0.9727],\n",
       "         [0.7021, 0.7701]],\n",
       "\n",
       "        [[0.6351, 0.7202],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5780, 0.6793],\n",
       "         [0.9949, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7019, 0.7704]],\n",
       "\n",
       "        [[0.6355, 0.7198],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5767, 0.6778],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7017, 0.7700]],\n",
       "\n",
       "        [[0.6354, 0.7199],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5754, 0.6778],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9725],\n",
       "         [0.7017, 0.7699]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_explain.nn.concepts import SignRelevanceAttention, SignRelevanceNet, WeightedMerger\n",
    "sra = SignRelevanceAttention(c_pred.shape[1], y_train.shape[1])\n",
    "srn = SignRelevanceNet(c_pred.shape[1], y_train.shape[1])\n",
    "wm = WeightedMerger(c_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, sign_attn, filter_attn = task_predictor(c_emb, c_pred, return_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_emb.shape , c_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex0 = [item['explanation'] for item in global_explanations if item['class'] == 'y_0']\n",
    "gex1 = [item['explanation'] for item in global_explanations if item['class'] == 'y_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_exp0 = \"|\".join(gex0)\n",
    "aggregated_exp1 = \"|\".join(gex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(c_{0} \\wedge c_{1}\\right) \\vee \\left(\\neg c_{0} \\wedge \\neg c_{1}\\right)$"
      ],
      "text/plain": [
       "(c_0 & c_1) | (~c_0 & ~c_1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy.logic.boolalg import to_dnf\n",
    "to_dnf(aggregated_exp0, simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(c_{0} \\wedge \\neg c_{1}\\right) \\vee \\left(c_{1} \\wedge \\neg c_{0}\\right)$"
      ],
      "text/plain": [
       "(c_0 & ~c_1) | (c_1 & ~c_0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dnf(aggregated_exp1, simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
