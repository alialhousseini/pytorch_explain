{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_explain.nn.concepts import ConceptReasoningLayer, IntpLinearLayer, ConceptReasoningLayerMod, ReasoningLinearLayer\n",
    "import torch\n",
    "import torch_explain as te\n",
    "from torch_explain import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, c, y = datasets.trigonometry(100)\n",
    "x_train, x_test, c_train, c_test, y_train, y_test = train_test_split(\n",
    "    x, c, y, test_size=0.33, random_state=42)\n",
    "\n",
    "embedding_size = 8\n",
    "concept_encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(x.shape[1], 10),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    te.nn.ConceptEmbedding(10, c.shape[1], embedding_size),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------#\n",
    "\n",
    "y_train = F.one_hot(y_train.long().ravel()).float()\n",
    "y_test = F.one_hot(y_test.long().ravel()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 3, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_encoder(x_train)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_predictor = ConceptReasoningLayer(embedding_size, y_train.shape[1])\n",
    "model = torch.nn.Sequential(concept_encoder, task_predictor)\n",
    "\n",
    "model.train()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "# loss = torch.nn.BCELoss()\n",
    "# c_emb, c_pred = concept_encoder(x_train)\n",
    "# print(c_emb.shape, c_pred.shape)\n",
    "# y_pred , sign_attn , filter_attn = task_predictor(c_emb, c_pred, return_attn=True)\n",
    "# print(y_pred.shape, sign_attn.shape, filter_attn.shape)\n",
    "\n",
    "# global_explainer = ReasoningLinearLayer(sign_attn.shape[1], filter_attn.shape[1], y_train.shape[1], log=True, modality='Attention')\n",
    "# global_explainer.train()\n",
    "# global_explainer(sign_attn, filter_attn, y_train)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "# loss_form = torch.nn.BCELoss()\n",
    "loss_form = torch.nn.BCEWithLogitsLoss()\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # generate concept and task predictions\n",
    "    c_emb, c_pred = concept_encoder(x_train)\n",
    "    y_pred = task_predictor(c_emb, c_pred)\n",
    "    \n",
    "\n",
    "    # compute loss\n",
    "    concept_loss = loss_form(c_pred, c_train)\n",
    "    task_loss = loss_form(y_pred, y_train)\n",
    "    loss = concept_loss + 0.5*task_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "local_explanations = task_predictor.explain(c_emb, c_pred, 'local')\n",
    "global_explanations = task_predictor.explain(c_emb, c_pred, 'global')\n",
    "\n",
    "# # print(local_explanations)\n",
    "# print(global_explanations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_explain.nn.concepts import ConceptReasoningLayerMod\n",
    "dcrm = ConceptReasoningLayerMod(embedding_size, y_train.shape[1], log=False)\n",
    "dcrm(c_emb, c_pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6354, 0.7199],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5767, 0.6782],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7018, 0.7699]],\n",
       "\n",
       "        [[0.6355, 0.7198],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5758, 0.6773],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7017, 0.7698]],\n",
       "\n",
       "        [[0.6358, 0.7197],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5781, 0.6755],\n",
       "         [0.9948, 0.9960],\n",
       "         [0.9640, 0.9727],\n",
       "         [0.7021, 0.7701]],\n",
       "\n",
       "        [[0.6351, 0.7202],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5780, 0.6793],\n",
       "         [0.9949, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7019, 0.7704]],\n",
       "\n",
       "        [[0.6355, 0.7198],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5767, 0.6778],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9726],\n",
       "         [0.7017, 0.7700]],\n",
       "\n",
       "        [[0.6354, 0.7199],\n",
       "         [0.9998, 0.9998],\n",
       "         [0.5754, 0.6778],\n",
       "         [0.9948, 0.9961],\n",
       "         [0.9640, 0.9725],\n",
       "         [0.7017, 0.7699]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_explain.nn.concepts import SignRelevanceAttention, SignRelevanceNet, WeightedMerger\n",
    "sra = SignRelevanceAttention(c_pred.shape[1], y_train.shape[1])\n",
    "srn = SignRelevanceNet(c_pred.shape[1], y_train.shape[1])\n",
    "wm = WeightedMerger(c_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'y_1', 'explanation': 'c_0 & c_1 & c_2', 'count': 31}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, sign_attn, filter_attn = task_predictor(c_emb, c_pred, return_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([67, 3, 8]), torch.Size([67, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_emb.shape , c_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex0 = [item['explanation'] for item in global_explanations if item['class'] == 'y_0']\n",
    "gex1 = [item['explanation'] for item in global_explanations if item['class'] == 'y_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_exp0 = \"|\".join(gex0)\n",
    "aggregated_exp1 = \"|\".join(gex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SympifyError",
     "evalue": "Sympify of expression 'could not parse ''' failed, because of exception being raised:\nSyntaxError: invalid syntax (<string>, line 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;31mValueError\u001b[0m: Error from parse_expr with transformed code: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\Github\\pytorch_explain\\env\\Lib\\site-packages\\sympy\\core\\sympify.py:493\u001b[0m, in \u001b[0;36msympify\u001b[1;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[0;32m    492\u001b[0m     a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 493\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43mparse_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (TokenError, \u001b[38;5;167;01mSyntaxError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\Github\\pytorch_explain\\env\\Lib\\site-packages\\sympy\\parsing\\sympy_parser.py:1090\u001b[0m, in \u001b[0;36mparse_expr\u001b[1;34m(s, local_dict, transformations, global_dict, evaluate)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     local_dict[i] \u001b[38;5;241m=\u001b[39m null\n\u001b[1;32m-> 1090\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from parse_expr with transformed code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Github\\pytorch_explain\\env\\Lib\\site-packages\\sympy\\parsing\\sympy_parser.py:1081\u001b[0m, in \u001b[0;36mparse_expr\u001b[1;34m(s, local_dict, transformations, global_dict, evaluate)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1081\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43meval_expr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# restore neutral definitions for names\u001b[39;00m\n",
      "File \u001b[1;32md:\\Github\\pytorch_explain\\env\\Lib\\site-packages\\sympy\\parsing\\sympy_parser.py:909\u001b[0m, in \u001b[0;36meval_expr\u001b[1;34m(code, local_dict, global_dict)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;124;03mEvaluate Python code generated by ``stringify_expr``.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \n\u001b[0;32m    907\u001b[0m \u001b[38;5;124;03mGenerally, ``parse_expr`` should be used.\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 909\u001b[0m expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# take local objects in preference\u001b[39;00m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "\u001b[1;31mSyntaxError\u001b[0m: invalid syntax (<string>, line 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSympifyError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboolalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_dnf\n\u001b[1;32m----> 2\u001b[0m \u001b[43mto_dnf\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregated_exp0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimplify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Github\\pytorch_explain\\env\\Lib\\site-packages\\sympy\\logic\\boolalg.py:1740\u001b[0m, in \u001b[0;36mto_dnf\u001b[1;34m(expr, simplify, force)\u001b[0m\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dnf\u001b[39m(expr, simplify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m    Convert a propositional logical sentence ``expr`` to disjunctive normal\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;124;03m    form: ``((A & ~B & ...) | (B & C & ...) | ...)``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1738\u001b[0m \n\u001b[0;32m   1739\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1740\u001b[0m     expr \u001b[38;5;241m=\u001b[39m \u001b[43msympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expr, BooleanFunction):\n\u001b[0;32m   1742\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "File \u001b[1;32md:\\Github\\pytorch_explain\\env\\Lib\\site-packages\\sympy\\core\\sympify.py:495\u001b[0m, in \u001b[0;36msympify\u001b[1;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[0;32m    493\u001b[0m     expr \u001b[38;5;241m=\u001b[39m parse_expr(a, local_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, transformations\u001b[38;5;241m=\u001b[39mtransformations, evaluate\u001b[38;5;241m=\u001b[39mevaluate)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (TokenError, \u001b[38;5;167;01mSyntaxError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SympifyError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not parse \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m a, exc)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "\u001b[1;31mSympifyError\u001b[0m: Sympify of expression 'could not parse ''' failed, because of exception being raised:\nSyntaxError: invalid syntax (<string>, line 0)"
     ]
    }
   ],
   "source": [
    "from sympy.logic.boolalg import to_dnf\n",
    "to_dnf(aggregated_exp0, simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(c_{0} \\wedge \\neg c_{1}\\right) \\vee \\left(c_{1} \\wedge \\neg c_{0}\\right)$"
      ],
      "text/plain": [
       "(c_0 & ~c_1) | (c_1 & ~c_0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dnf(aggregated_exp1, simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
