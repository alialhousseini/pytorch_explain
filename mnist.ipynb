{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "def load_mnist(image_path, label_path):\n",
    "    images = read_idx(image_path)\n",
    "    labels = read_idx(label_path)\n",
    "    return images, labels\n",
    "\n",
    "train_image_path = './MNIST/train-images-idx3-ubyte/train-images-idx3-ubyte'\n",
    "train_label_path = './MNIST/train-labels-idx1-ubyte/train-labels-idx1-ubyte'\n",
    "test_image_path =  './MNIST/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte'\n",
    "test_label_path =  './MNIST/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = load_mnist(train_image_path, train_label_path)\n",
    "test_images, test_labels = load_mnist(test_image_path, test_label_path)\n",
    "print(f'Train images shape: {train_images.shape}')\n",
    "print(f'Train labels shape: {train_labels.shape}')\n",
    "print(f'Test images shape: {test_images.shape}')\n",
    "print(f'Test labels shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractor.avg import AVG\n",
    "from extractor.resnet import ResNet\n",
    "from torch_explain.nn.concepts import ConceptReasoningLayer, ConceptEmbedding\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch_explain as te\n",
    "from torch_explain import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, c, y = datasets.xor(500)\n",
    "x_train, x_test, c_train, c_test, y_train, y_test = train_test_split(\n",
    "    x, c, y, test_size=0.33, random_state=42)\n",
    "\n",
    "x_train = x_train[:10]\n",
    "x_test = x_test[:10]\n",
    "c_train = c_train[:10]\n",
    "c_test = c_test[:10]\n",
    "y_train = y_train[:10]\n",
    "y_test = y_test[:10]\n",
    "\n",
    "embedding_size = 8\n",
    "concept_encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(x.shape[1], 10),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    te.nn.ConceptEmbedding(10, c.shape[1], embedding_size),\n",
    ")\n",
    "\n",
    "\n",
    "c_emb, c_pred = concept_encoder.forward(x_test)\n",
    "\n",
    "\n",
    "# -------------------------------------#\n",
    "\n",
    "y_train = F.one_hot(y_train.long().ravel()).float()\n",
    "y_test = F.one_hot(y_test.long().ravel()).float()\n",
    "\n",
    "\n",
    "task_predictor = ConceptReasoningLayer(\n",
    "    embedding_size, y_train.shape[1], log=True)\n",
    "model = torch.nn.Sequential(concept_encoder, task_predictor)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss_form = torch.nn.BCELoss()\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # generate concept and task predictions\n",
    "    c_emb, c_pred = concept_encoder(x_train)\n",
    "    y_pred = task_predictor(c_emb, c_pred)\n",
    "\n",
    "    # compute loss\n",
    "    concept_loss = loss_form(c_pred, c_train)\n",
    "    task_loss = loss_form(y_pred, y_train)\n",
    "    loss = concept_loss + 0.5*task_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "local_explanations = task_predictor.explain(c_emb, c_pred, 'local')\n",
    "global_explanations = task_predictor.explain(c_emb, c_pred, 'global')\n",
    "\n",
    "# print(local_explanations)\n",
    "print(global_explanations)\n",
    "\n",
    "\n",
    "# task_predictor = ConceptReasoningLayer(embedding_size, y_train.shape[1])\n",
    "# model = torch.nn.Sequential(concept_encoder, task_predictor)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "# loss_form = torch.nn.BCELoss()\n",
    "# model.train()\n",
    "# for epoch in range(501):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # generate concept and task predictions\n",
    "#     c_emb, c_pred = concept_encoder(x_train)\n",
    "#     y_pred = task_predictor(c_emb, c_pred)\n",
    "\n",
    "#     # compute loss\n",
    "#     concept_loss = loss_form(c_pred, c_train)\n",
    "#     task_loss = loss_form(y_pred, y_train)\n",
    "#     loss = concept_loss + 0.5*task_loss\n",
    "\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# local_explanations = task_predictor.explain(c_emb, c_pred, 'local')\n",
    "# global_explanations = task_predictor.explain(c_emb, c_pred, 'global')\n",
    "\n",
    "# # print(local_explanations)\n",
    "# print(global_explanations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_flat = train_images.reshape(train_images.shape[0], -1)\n",
    "test_images_flat = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "X_train = train_images_flat\n",
    "y_train = train_labels\n",
    "X_test = test_images_flat\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
